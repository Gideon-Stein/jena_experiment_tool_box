{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vol10     0\n",
      "Vol20     0\n",
      "Vol30     0\n",
      "Vol40     0\n",
      "Vol60     4\n",
      "Vol100    5\n",
      "dtype: int64\n",
      "Vol10     0\n",
      "Vol20     0\n",
      "Vol30     0\n",
      "Vol40     0\n",
      "Vol60     0\n",
      "Vol100    7\n",
      "dtype: int64\n",
      "Vol10      0\n",
      "Vol20      0\n",
      "Vol30      0\n",
      "Vol40      5\n",
      "Vol60      0\n",
      "Vol100    14\n",
      "dtype: int64\n",
      "Vol10       3\n",
      "Vol20       1\n",
      "Vol30       1\n",
      "Vol40      12\n",
      "Vol60     207\n",
      "Vol100    573\n",
      "dtype: int64\n",
      "Vol10     1\n",
      "Vol20     0\n",
      "Vol30     0\n",
      "Vol40     3\n",
      "Vol60     0\n",
      "Vol100    1\n",
      "dtype: int64\n",
      "Vol10       0\n",
      "Vol20       0\n",
      "Vol30       0\n",
      "Vol40       0\n",
      "Vol60       0\n",
      "Vol100    745\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Combine table and format datetime\n",
    "# paths:\n",
    "base_path = \"/home/datasets4/stein\"\n",
    "data_root = f\"{base_path}/jena_experiment_data_raw/jena_experiment\"\n",
    "output_root = f\"{base_path}/jena_experiment_data_various_products/covariates_processed\"\n",
    "stack = []\n",
    "mypath = f\"{data_root}/moisture\"\n",
    "onlyfiles = [f.split(\"D\")[0] for f in listdir(mypath)]\n",
    "for folder in onlyfiles: \n",
    "   p = mypath +  \"/\" + folder + \"Dataset\" + \"/\" + folder + \"data.csv\"\n",
    "   stack.append(pd.read_csv(p, on_bad_lines='skip', sep= \";\"))\n",
    "# group for the sample and rake the mean\n",
    "for x in range(len(stack)):\n",
    "    # extract hour for meaning\n",
    "    # remove extreme % values (only up because drought seems to be possible under 5)\n",
    "    problem = stack[x][[\"Vol10\",\"Vol20\",\"Vol30\",\"Vol40\",\"Vol60\",\"Vol100\"]] > 70\n",
    "    print(problem.sum())\n",
    "    stack[x][problem] = np.nan \n",
    "    stack[x][\"time\"] = pd.to_datetime(stack[x][\"time\"]).dt.hour\n",
    "    stack[x] = stack[x].drop(columns = [\"sample\", \"comment\"]).groupby([\"plot\", \"date\"]).mean(numeric_only=True).reset_index()\n",
    "    #reformat to time to add it to the datetime stamp.\n",
    "    stack[x][\"time\"] = pd.to_datetime(stack[x][\"time\"], format=\"%H\")\n",
    "    #update the date with the mean hour\n",
    "    stack[x][\"datetime\"] = stack[x][\"date\"] + \" \" +  stack[x][\"time\"].astype(str).str[-8:]\n",
    "    stack[x] = stack[x].drop(columns = [\"date\", \"time\"])\n",
    "\n",
    "sm = pd.concat(stack).sort_values(\"datetime\").reset_index(drop=True)\n",
    "# reorder columns\n",
    "sm = sm[[\"datetime\", \"plot\",\"Vol10\",\"Vol20\",\"Vol30\",\"Vol40\",\"Vol60\",\"Vol100\"]]\n",
    "sm.to_csv(f\"{output_root}/moisture_base.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2663960/4286036191.py:4: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  moisture[\"week\"] = moisture[\"datetime\"].dt.week\n"
     ]
    }
   ],
   "source": [
    "moisture = pd.read_csv(f\"{output_root}/moisture_base.csv\")\n",
    "moisture[\"datetime\"] = pd.to_datetime(moisture[\"datetime\"])\n",
    "moisture.sort_values(\"datetime\", inplace = True)\n",
    "moisture[\"week\"] = moisture[\"datetime\"].dt.week\n",
    "moisture[\"year\"] = moisture[\"datetime\"].dt.year\n",
    "moisture.drop(columns= [\"datetime\"])\n",
    "\n",
    "# mean for events where measurements were taken on multiple days in the week. \n",
    "moisture = moisture.groupby([\"year\", \"week\", \"plot\"]).mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore winter months:  (10 Because most years start roughly at least there with measurements)\n",
    "m = moisture[(moisture[\"week\"] >=  13) & (moisture[\"week\"] <=  43)]\n",
    "# Remove 2002 because its measured very late and plant div is not establised anyways\n",
    "m = m[m[\"year\"] != 2002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to fill potential missing points.\n",
    "# First we calculate the mean for each time stamp and try to fill with this as good as it is possible.\n",
    "# After this we use the seasonal mean of each plot.\n",
    "meansV = m.groupby([\"week\", \"year\"]).mean().reset_index()\n",
    "meansV = m[[\"year\", \"week\", \"plot\"]].merge(meansV, on= [\"year\", \"week\"], how = \"left\")\n",
    "meansH = m[m.columns[1:]].groupby([\"week\", \"plot\"]).mean().reset_index()\n",
    "meansH = m[[\"year\", \"week\", \"plot\"]].merge(meansH, on= [\"week\", \"plot\"], how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.048802543683089755\n",
      "0.010501443948542924\n",
      "0.010443102593273242\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Fill with week mean\n",
    "print((m.isnull().sum() / len(m))[\"Vol10\"])\n",
    "for x in m.columns: \n",
    "    index = m[x].isnull().values\n",
    "    m.loc[index, x] = meansV.loc[index, x].values\n",
    "print((m.isnull().sum() / len(m))[\"Vol10\"])\n",
    "# If there are small week gaps we can interpolate directly. \n",
    "m = m.interpolate(limit = 1)\n",
    "print((m.isnull().sum() / len(m))[\"Vol10\"])\n",
    "\n",
    "# Remaining with seasonal mean\n",
    "for x in m.columns: \n",
    "    index = m[x].isnull().values\n",
    "    m.loc[index, x] = meansH.loc[index, x].values\n",
    "print((m.isnull().sum() / len(m))[\"Vol10\"])\n",
    "\n",
    "# Fill the tiny rest for which no seasonal mean exists\n",
    "m = m.interpolate(limit = 1)\n",
    "print((m.isnull().sum() / len(m))[\"Vol10\"])\n",
    "\n",
    "\n",
    "m.to_csv(f\"{output_root}/moisture_weekly_filled.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yearly product.\n",
    "m = pd.read_csv(f\"{output_root}/moisture_weekly_filled.csv\")\n",
    "m = m.drop(columns=\"week\")\n",
    "yearly = m.groupby([\"year\", \"plot\"])\n",
    "mean = yearly.mean()\n",
    "std = yearly.std()\n",
    "stab = mean / std\n",
    "\n",
    "mean.columns = [x + \"_mean\" for x in mean.columns]\n",
    "std.columns = [x + \"_std\" for x in std.columns]\n",
    "stab.columns = [x + \"_stab\" for x in stab.columns]\n",
    "\n",
    "yearly = pd.concat([mean, std, stab], axis = 1).reset_index()\n",
    "yearly.to_csv(f\"{output_root}/moisture_yearly.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "process_data_jena",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
