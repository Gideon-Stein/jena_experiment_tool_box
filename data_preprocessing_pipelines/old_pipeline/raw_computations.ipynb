{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68b977fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join, isdir\n",
    "import numpy as np; np.random.seed(0)\n",
    "import seaborn as sns; sns.set_theme()\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a08858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Canbus_Data/Complete-HeaderFile_extendedBasedOn20173020605_V4.csv\"\n",
    "head = pd.read_csv(path, encoding= 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dedd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_name(name):\n",
    "    t = name[2:-4]\n",
    "    date = datetime(int(t[:4]), 1, 1,int(t[7:9]), int(t[9:11])) + timedelta(int(t[4:7]) - 1)\n",
    "    return date\n",
    "\n",
    "def transform_date(date):\n",
    "    date = date[:6] + date[8:-3]\n",
    "    dt = datetime.strptime(date, '%d.%m.%y %H:%M:%S')\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5020c9d1-dc21-4e09-8154-6e0b127c0466",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables, tables_list = get_all_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0c7fc8-f991-4009-8d7b-4d580a3dad30",
   "metadata": {},
   "source": [
    "### Check for empty files and missing columns"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d64aa751-4bfe-481a-ab7f-a210091e56cc",
   "metadata": {},
   "source": [
    "missing_data = []\n",
    "missingColumns = {}\n",
    "for x in tables_list:\n",
    "    try:\n",
    "        data = pd.read_csv(x, encoding= 'unicode_escape')\n",
    "    except: \n",
    "        missing_data.append(x)\n",
    "    missing = []\n",
    "    for y in head.columns: \n",
    "        if y not in data.columns: \n",
    "            missing.append(y)\n",
    "    missingColumns[x] = missing\n",
    "pickle.dump(missingColumns, open(\"missingColumns.p\", \"wb\"))\n",
    "pickle.dump(missing_data, open(\"missingData.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88311aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "missingColumns = pickle.load(open(\"missingColumns.p\", \"rb\"))\n",
    "missingData = pickle.load(open(\"missingData.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e21f8d0-dd51-4450-ab84-1b3f8267747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in missingData: #Fix small mistake in the earlier loop\n",
    "    del missingColumns[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8138717a-cc4c-4de8-b7bb-8346bc925a5f",
   "metadata": {},
   "source": [
    "### How many columns do they files have?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2649d2c7-b97f-4200-8c5a-4cc83af6fa4e",
   "metadata": {},
   "source": [
    "columns_length = {}\n",
    "for x in range(0,len(tables_list)): \n",
    "    if x%1000 ==0 : \n",
    "        print(x)\n",
    "    try:\n",
    "        data = pd.read_csv(tables_list[x], encoding= 'unicode_escape')\n",
    "        columns_length[tables_list[x]] =  len(data.columns)\n",
    "    except: \n",
    "        columns_length[x] = 0\n",
    "pickle.dump(columns_length, open(\"columnsLength.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1eb21eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_length = pickle.load(open(\"columnsLength.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90120c6-bebe-47ed-a5c5-f6574536eb21",
   "metadata": {},
   "source": [
    "### Check for date differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c1d4d0-ba89-40e0-98e0-b0ccf095830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_differences = []\n",
    "for x in tables_list:\n",
    "    try:\n",
    "        a = pd.read_csv(x, encoding= 'unicode_escape')[\"t[s]\"][0]\n",
    "        one = transform_date(a)\n",
    "        two = transform_name(x.split(\"/\")[-1])\n",
    "        if one > two: \n",
    "            diff = one - two \n",
    "        else: \n",
    "            diff = two - one\n",
    "        date_differences.append(diff.total_seconds())\n",
    "    except: \n",
    "        date_differences.append(-1) \n",
    "pickle.dump(date_differences, open(\"dateDifferences.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d762442b-cb6a-4679-8ce6-7043378570a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = pickle.load(open(\"dateDifferences.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dff472-5293-4f5c-bf12-80b1eda2422e",
   "metadata": {},
   "source": [
    "### Detect dupliate lines"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c938c6b2-e389-4860-99bf-725435f4d1ea",
   "metadata": {},
   "source": [
    "duplicates = []\n",
    "columns_length = {}\n",
    "data_before = pd.read_csv(tables_list[0], encoding= 'unicode_escape')['t[s]']\n",
    "for x in range(1,len(tables_list)): \n",
    "    if x%1000 ==0 : \n",
    "        print(x)\n",
    "    try:\n",
    "        data = pd.read_csv(tables_list[x], encoding= 'unicode_escape')['t[s]']\n",
    "        if np.any(data.values[0] == data_before.values):\n",
    "            duplicates.append(tables_list[x])        \n",
    "    except: \n",
    "        pass\n",
    "    data_before = data                        \n",
    "pickle.dump(duplicates, open(\"detectedDuplicates.p\", \"wb\"))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f485c2-bd53-4652-848a-6a90b9eba0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = pickle.load(open(\"detectedDuplicates.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe4eb98-e4df-4e7d-bff3-5d179168a32b",
   "metadata": {},
   "source": [
    "### Calculate the overlap"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fdefa0b7-6376-47fa-98cd-e635b9644581",
   "metadata": {},
   "source": [
    "overlap = []\n",
    "data_before = pd.read_csv(duplicates[0], encoding= 'unicode_escape')['t[s]']\n",
    "for x in range(1,len(duplicates)): \n",
    "    if x%1000 ==0 : \n",
    "        print(x)\n",
    "    try:\n",
    "        data = pd.read_csv(duplicates[x], encoding= 'unicode_escape')['t[s]']\n",
    "        if np.any(data.values[0] == data_before.values):\n",
    "            overlap.append(np.where(data_before.values == data.values[0])[0][0])        \n",
    "    except:\n",
    "        pass\n",
    "    data_before = data                        \n",
    "pickle.dump(overlap, open(\"overlap.p\", \"wb\"))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9279f52a-d986-4f29-9113-4bd93345ad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = pickle.load(open(\"overlap.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85e95e3-16bb-4abb-909b-2a628c725c29",
   "metadata": {},
   "source": [
    "### Check for columns that do not exist in the header file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d34db52-eca3-46b1-bae2-0102d3e9e284",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Canbus_Data/Complete-HeaderFile_extendedBasedOn20173020605_V4.csv\"\n",
    "head = pd.read_csv(path, encoding= 'unicode_escape')\n",
    "additional = {}\n",
    "for x in tables_list:\n",
    "    try:\n",
    "        data = pd.read_csv(x, encoding= 'unicode_escape')\n",
    "        missing = []\n",
    "        for y in data.columns: \n",
    "            if y not in head.columns: \n",
    "                missing.append(y)\n",
    "        additional[x] = missing\n",
    "    except: \n",
    "        pass\n",
    "pickle.dump(additional, open(\"additionalColumns.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f655463-edc4-410b-ab9c-f90133a415d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = pickle.load(open(\"raw_stats/additionalColumns.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611c699d-95b6-4b04-95ac-f32b146a0362",
   "metadata": {},
   "source": [
    "### Get all missing names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec4dbcb-d84c-4346-8056-a7c7d107910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all broken column names\n",
    "names = []\n",
    "for key in col: \n",
    "    for value in col[key]:\n",
    "        names.append(value)\n",
    "temp = []\n",
    "for x in names: \n",
    "    if \"Unnamed\" in x: \n",
    "        pass\n",
    "    else: \n",
    "        temp.append(x)\n",
    "names = list(set(temp))\n",
    "pickle.dump(names, open(\"raw_stats/additionalColumnNames.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2637d547-a947-47d2-93fc-c7e984847a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = pickle.load(open(\"raw_stats/additionalColumnNames.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcf7e7d-4adf-444c-8a98-64ca6048b04d",
   "metadata": {},
   "source": [
    "### Create a mapping from wrong to correct column name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31056aaa-18f1-4f96-87b4-a2f45c8b5d5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mapping = {}\n",
    "for x in head.columns[1:-1]: \n",
    "      mapping[x] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85de795b-9621-4e60-8a4f-e03278ef20e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual = []\n",
    "for x in names: \n",
    "    if \"[_]\" in x:\n",
    "        try: \n",
    "            spotted = list(head).index(x[:-3] + \"[°C]\")\n",
    "            mapping[x[:-3] + \"[°C]\"].append(x)\n",
    "        except:\n",
    "            manual.append(x)\n",
    "    else:\n",
    "        manual.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd689208-7947-44e1-994b-8a8df6ebc690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['soil_temp_15cm_depth_3A06M[_]',\n",
       " 'soil_temp_05cm_depth_3A06M[_]',\n",
       " 'soil_temp_05cm_depth_3A06M[°C]',\n",
       " 'soil_temp_15cm_depth_3A06M[°C]']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76c96e86-add3-4825-a5b5-2dfba40f88f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soil_temp_15cm_depth_3A06N[°C]\n"
     ]
    }
   ],
   "source": [
    "for x in mapping.keys():\n",
    "    if \"soil_temp_15cm_depth_3A06\" in x: \n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a0dcd8b-df25-4937-ab00-1e59d8b0efae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soil_temp_05cm_depth_3A06N[°C]\n"
     ]
    }
   ],
   "source": [
    "for x in mapping.keys():\n",
    "    if \"soil_temp_05cm_depth_3A06\" in x: \n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58699de5-98bf-4f3a-91f5-7c5c2781ac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually add these 4:\n",
    "\n",
    "mapping[\"soil_temp_05cm_depth_3A06N[°C]\"].append(manual[1])\n",
    "mapping[\"soil_temp_05cm_depth_3A06N[°C]\"].append(manual[2])\n",
    "mapping[\"soil_temp_15cm_depth_3A06N[°C]\"].append(manual[0])\n",
    "mapping[\"soil_temp_15cm_depth_3A06N[°C]\"].append(manual[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11563f9d-6d7d-4af4-b34c-94d905f7f657",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(mapping, open(\"raw_stats/mappingWrongColumns.p\", \"wb\"))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4379557-4d24-492f-986c-3958e16857e7",
   "metadata": {},
   "source": [
    "### Everything table with more than 1 day time difference should be fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a9d014-5e1a-4a06-9379-debae55e9969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# everything with more than one day difference should be corrected: \n",
    "differences = pickle.load(open(\"raw_stats/dateDifferences.p\", \"rb\"))\n",
    "corrected_list = []\n",
    "for x in range(len(differences)):\n",
    "    if differences[x] > 86400:\n",
    "        correction = transform_doc_time(tables_list[x])\n",
    "        corrected_list.append(tables_list[x])\n",
    "        correction.to_csv(\"time_changes/\" + tables_list[x].split(\"/\")[-1])\n",
    "pickle.dump(corrected_list, open(\"raw_stats/corrected_list.p\", \"wb\"))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837054d9-7abf-4e2f-9a5d-5e113bb00ef7",
   "metadata": {},
   "source": [
    "### Get a full timeline\n",
    "- Idea: Drop Seconds. And spread.\n",
    "- A minute in the new set is then from 0. -59 of this minute.\n",
    "- Should be a minimal generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f2dcba2-ecb4-47bb-b062-ea2999272628",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeLine = [transform_date(x) for x in pickle.load(open(\"data_transform/timeLine.p\", \"rb\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bb60ad9-c61a-4c9f-ab65-8056151d449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullTime = (timeLine[-1] - timeLine[0]).days *24 * 60 + ((timeLine[-1] - timeLine[0]).seconds + 11) / 60\n",
    "start = timeLine[0].replace(second=0)\n",
    "completeLine = [start]\n",
    "for x in range(1,int(fullTime)+1):\n",
    "    completeLine.append(start + timedelta(minutes=x ) )\n",
    "pickle.dump(completeLine, open(\"raw_stats/completeTime.p\", \"wb\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7a1925e-c6f4-428c-aec9-233ef3c98b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "completeTime = pickle.load(open(\"raw_stats/completeTime.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2db1a05-5980-4c29-b42a-a121988bcce0",
   "metadata": {},
   "source": [
    "### Get a rounded timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "025e0116-9471-4bda-b864-91ae49f6fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeLine = [transform_date(x) for x in pickle.load(open(\"data_transform/timeLine.p\", \"rb\"))]\n",
    "for x in range(len(timeLine)):\n",
    "    timeLine[x] = timeLine[x].replace(second=0)\n",
    "pickle.dump(timeLine, open(\"raw_stats/timeLineRounded.p\", \"wb\"))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ec8567-9652-4294-933c-2bf5a51ecb85",
   "metadata": {},
   "source": [
    "### Gaps between timeline steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e93eeb5-7971-43ac-8829-4b32a7f188a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeLine = pickle.load(open(\"raw_stats/timeLineRounded.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2d114d9-2a34-4db6-bc2e-375c87f37660",
   "metadata": {},
   "outputs": [],
   "source": [
    "gapLine = []\n",
    "for x in range(len(timeLine)-1): \n",
    "    gapLine.append(timeLine[x+1] - timeLine[x])\n",
    "pickle.dump(gapLine, open(\"raw_stats/gapLine.p\", \"wb\"))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
